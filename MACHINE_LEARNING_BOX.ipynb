{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " MACHINE LEARNING BOX",
      "provenance": [],
      "authorship_tag": "ABX9TyMu/wlIjwaULgg1vqPyzueq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartikeyaGUPTA45/AUTOMATED-MACHINE-LEARNING/blob/master/MACHINE_LEARNING_BOX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMH4ISF2L1W1",
        "colab_type": "text"
      },
      "source": [
        "# MACHINE LEARNING BOX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEZEwG6lMAN3",
        "colab_type": "text"
      },
      "source": [
        "# INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp3u9TjFNaQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd983e55-f40f-4a58-97ce-4db6704fa339"
      },
      "source": [
        "!pip install setuptools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (46.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8MBKgOqNwsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1fe1e65e-878d-463f-8944-96ba23832e95"
      },
      "source": [
        "!pip install wheel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (0.34.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqWh-3DCNzNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "723a810a-748e-4912-8584-116cf24e6e9a"
      },
      "source": [
        "!pip install mlbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mlbox\n",
            "  Downloading https://files.pythonhosted.org/packages/51/13/bafe2164ce8b476c0ffccc7eda8b42e28f2c07c53c7077e115d99e57c139/mlbox-0.8.4.tar.gz\n",
            "Collecting numpy==1.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/08/a549ba8b061005bb629b76adc000f3caaaf881028b963c2e18f811c6edc1/numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from mlbox) (1.4.1)\n",
            "Collecting matplotlib==3.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0MB 174kB/s \n",
            "\u001b[?25hCollecting hyperopt==0.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/11/8bbbb5edb78c40a2bd0f6b730e3dc0f29ffbaea9a59520eb9622951e9151/hyperopt-0.2.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 44.6MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 35.0MB/s \n",
            "\u001b[?25hCollecting joblib==0.14.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 49.7MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 40.8MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/16/b07e3f7a4a024b47918f7018967eb984b0c542458a6141d8c48515aa81d4/tensorflow-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 47kB/s \n",
            "\u001b[?25hCollecting lightgbm==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 44.9MB/s \n",
            "\u001b[?25hCollecting tables==3.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/f7/bb0ec32a3f3dd74143a3108fbf737e6dcfd47f0ffd61b52af7106ab7a38a/tables-3.5.2-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 16.0MB/s \n",
            "\u001b[?25hCollecting xlrd==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3->mlbox) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3->mlbox) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3->mlbox) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.3->mlbox) (1.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.2.3->mlbox) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.2.3->mlbox) (4.41.1)\n",
            "Collecting networkx==2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/f4/7e20ef40b118478191cec0b58c3192f822cace858c19505c7670961b76b2/networkx-2.2.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.2.3->mlbox) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.2.3->mlbox) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->mlbox) (2018.9)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (1.29.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (1.0.8)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.1->mlbox) (0.9.0)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables==3.5.2->mlbox) (2.7.1)\n",
            "Collecting mock>=2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx==2.2->hyperopt==0.2.3->mlbox) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.1->mlbox) (46.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (1.7.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.1->mlbox) (2.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (2020.4.5.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (1.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.1->mlbox) (0.4.8)\n",
            "Building wheels for collected packages: mlbox, networkx, gast\n",
            "  Building wheel for mlbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mlbox: filename=mlbox-0.8.4-cp36-none-any.whl size=43756 sha256=62a1e4a88a4ea501e7d66951c9435a50c64eda2e2156fd1cf433cbeaeb41c08e\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/47/56/277073efea0d7dfeae78248a2fed47f45756df51fff9ab5155\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.2-py2.py3-none-any.whl size=1527322 sha256=2d59d6b483eb46b97b489ba59981eacd716f16b4136006cebd1bbf5c94fd366c\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=9f04e2e2af7527af4de1238feb8e543c53cdd9e3b93471756095030639c96ca8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built mlbox networkx gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, matplotlib, networkx, hyperopt, pandas, joblib, scikit-learn, gast, tensorboard, tensorflow-estimator, tensorflow, lightgbm, mock, tables, xlrd, mlbox\n",
            "  Found existing installation: numpy 1.18.4\n",
            "    Uninstalling numpy-1.18.4:\n",
            "      Successfully uninstalled numpy-1.18.4\n",
            "  Found existing installation: matplotlib 3.2.1\n",
            "    Uninstalling matplotlib-3.2.1:\n",
            "      Successfully uninstalled matplotlib-3.2.1\n",
            "  Found existing installation: networkx 2.4\n",
            "    Uninstalling networkx-2.4:\n",
            "      Successfully uninstalled networkx-2.4\n",
            "  Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Found existing installation: pandas 1.0.3\n",
            "    Uninstalling pandas-1.0.3:\n",
            "      Successfully uninstalled pandas-1.0.3\n",
            "  Found existing installation: joblib 0.15.1\n",
            "    Uninstalling joblib-0.15.1:\n",
            "      Successfully uninstalled joblib-0.15.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "  Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "Successfully installed gast-0.2.2 hyperopt-0.2.3 joblib-0.14.1 lightgbm-2.3.1 matplotlib-3.0.3 mlbox-0.8.4 mock-4.0.2 networkx-2.2 numpy-1.18.2 pandas-0.25.3 scikit-learn-0.22.1 tables-3.5.2 tensorboard-2.0.2 tensorflow-2.0.1 tensorflow-estimator-2.0.1 xlrd-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmL2lRhgMLj8",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTING THE LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgz7UC5MN2SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mlbox.preprocessing import *\n",
        "from mlbox.optimisation import *\n",
        "from mlbox.prediction import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIUDet_DM075",
        "colab_type": "text"
      },
      "source": [
        "The list of paths to your train datasets and test datasets.\n",
        "\n",
        "The name of the target you try to predict (classification or regression)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdk_QNScOJzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths = [\"/content/train.csv\",\"/content/test.csv\"]\n",
        "target_name = \"Survived\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YGUhqSCNA41",
        "colab_type": "text"
      },
      "source": [
        "Read and preprocess  files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESGMvFkgSVUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "ee45be91-916d-4c60-da75-d7500ca36ee6"
      },
      "source": [
        "rd = Reader(sep = \",\")\n",
        "df = rd.train_test_split(paths, target_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "reading csv : train.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 0.07761740684509277 seconds\n",
            "\n",
            "reading csv : test.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 0.0636444091796875 seconds\n",
            "\n",
            "> Number of common features : 11\n",
            "\n",
            "gathering and crunching for train and test datasets ...\n",
            "reindexing for train and test datasets ...\n",
            "dropping training duplicates ...\n",
            "dropping constant variables on training set ...\n",
            "\n",
            "> Number of categorical features: 5\n",
            "> Number of numerical features: 6\n",
            "> Number of training samples : 891\n",
            "> Number of test samples : 418\n",
            "\n",
            "> Top sparse features (% missing values on train set):\n",
            "Cabin       77.1\n",
            "Age         19.9\n",
            "Embarked     0.2\n",
            "dtype: float64\n",
            "\n",
            "> Task : classification\n",
            "0.0    549\n",
            "1.0    342\n",
            "Name: Survived, dtype: int64\n",
            "\n",
            "encoding target ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NCbDyQUSdPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "9a328fa5-1d91-4bb8-9642-a643e9808697"
      },
      "source": [
        "dft = Drift_thresholder()\n",
        "df = dft.fit_transform(df)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "computing drifts ...\n",
            "CPU time: 0.23114228248596191 seconds\n",
            "\n",
            "> Top 10 drifts\n",
            "\n",
            "('PassengerId', 0.9976076555023923)\n",
            "('Name', 0.9918391604868151)\n",
            "('Ticket', 0.6607211797041628)\n",
            "('Cabin', 0.1784259875126053)\n",
            "('Embarked', 0.07957396812891337)\n",
            "('Fare', 0.061906334656292916)\n",
            "('SibSp', 0.052670910937572035)\n",
            "('Sex', 0.04688378053834308)\n",
            "('Parch', 0.046231313085776105)\n",
            "('Pclass', 0.024131640542976784)\n",
            "\n",
            "> Deleted variables : ['Name', 'PassengerId', 'Ticket']\n",
            "> Drift coefficients dumped into directory : save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiWvnWBHSmr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "9e0574b3-5ec8-450c-9178-0dfdab4c8976"
      },
      "source": [
        "data = Reader(sep=\",\").train_test_split(paths, target_name) #reading\n",
        "data = Drift_thresholder().fit_transform(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "reading csv : train.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 0.07999706268310547 seconds\n",
            "\n",
            "reading csv : test.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 0.06072688102722168 seconds\n",
            "\n",
            "> Number of common features : 11\n",
            "\n",
            "gathering and crunching for train and test datasets ...\n",
            "reindexing for train and test datasets ...\n",
            "dropping training duplicates ...\n",
            "dropping constant variables on training set ...\n",
            "\n",
            "> Number of categorical features: 5\n",
            "> Number of numerical features: 6\n",
            "> Number of training samples : 891\n",
            "> Number of test samples : 418\n",
            "\n",
            "> Top sparse features (% missing values on train set):\n",
            "Cabin       77.1\n",
            "Age         19.9\n",
            "Embarked     0.2\n",
            "dtype: float64\n",
            "\n",
            "> Task : classification\n",
            "0.0    549\n",
            "1.0    342\n",
            "Name: Survived, dtype: int64\n",
            "\n",
            "encoding target ...\n",
            "\n",
            "computing drifts ...\n",
            "CPU time: 0.22439098358154297 seconds\n",
            "\n",
            "> Top 10 drifts\n",
            "\n",
            "('PassengerId', 1.0)\n",
            "('Name', 0.991847043760365)\n",
            "('Ticket', 0.6772314666529091)\n",
            "('Cabin', 0.18592882681701628)\n",
            "('Embarked', 0.07750155917650425)\n",
            "('Parch', 0.07506274675911873)\n",
            "('Sex', 0.04520669244119446)\n",
            "('Fare', 0.03905251971842949)\n",
            "('Pclass', 0.01985625441324701)\n",
            "('Age', 0.007476139838183071)\n",
            "\n",
            "> Deleted variables : ['Name', 'PassengerId', 'Ticket']\n",
            "> Drift coefficients dumped into directory : save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOVahHMuV104",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e4942a3a-4ce3-463b-df04-085a0d6d108c"
      },
      "source": [
        "Optimiser().evaluate(None, data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlbox/optimisation/optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
            "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No parameters set. Default configuration is tested\n",
            "\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            "\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            "\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            "\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "\n",
            "\n",
            "MEAN SCORE : neg_log_loss = -0.6566934245807459\n",
            "VARIANCE : 0.03558843801215594 (fold 1 = -0.6922818625929018, fold 2 = -0.6211049865685899)\n",
            "CPU time: 0.39270901679992676 seconds\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.6566934245807459"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e4Q4is3Su-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "ae03f8a1-4d5e-437b-e847-847d38f9a552"
      },
      "source": [
        "space = {\n",
        "'ne__numerical_strategy' : {\"space\" : [0, 'mean']},\n",
        "'ce__strategy' : {\"space\" : [\"label_encoding\", \"random_projection\", \"entity_embedding\"]},\n",
        "\n",
        "'fs__threshold': {\"search\" : \"choice\", \"space\" : [0.1, 0.2, 0.3]},\n",
        "'est__strategy' : {\"space\" : [\"LightGBM\"]},\n",
        "'est__max_depth' : {\"search\" : \"choice\", \"space\" : [5,6]},\n",
        "'est__subsample' : {\"search\" : \"uniform\", \"space\" : [0.6,0.9]}\n",
        "}\n",
        "best = opt.optimise(space, data, max_evals = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'subsample': 0.7818576357531606, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -0.4483774227904051\n",
            "VARIANCE : 0.03127121283283283 (fold 1 = -0.49236596391733095, fold 2 = -0.4303314829119352, fold 3 = -0.42243482154194917)\n",
            "CPU time: 0.8289399147033691 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'subsample': 0.721325194257596, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -0.42447896705734856\n",
            "VARIANCE : 0.022659520922571383 (fold 1 = -0.4531966520035264, fold 2 = -0.42243482154194917, fold 3 = -0.39780542762657006)\n",
            "CPU time: 0.5918674468994141 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'subsample': 0.7620525196057667, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -0.44706740605683365\n",
            "VARIANCE : 0.032071825737685127 (fold 1 = -0.49236596391733095, fold 2 = -0.4264014327112209, fold 3 = -0.42243482154194917)\n",
            "CPU time: 0.7950375080108643 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'subsample': 0.8879700106196631, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -0.450245722713954\n",
            "VARIANCE : 0.02052621868876567 (fold 1 = -0.47849370837684896, fold 2 = -0.4303314829119352, fold 3 = -0.4419119768530779)\n",
            "CPU time: 0.6185829639434814 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.3}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'subsample': 0.7838153308693042, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -0.4246140642731732\n",
            "VARIANCE : 0.019968569902012984 (fold 1 = -0.4457052822810143, fold 2 = -0.4303314829119352, fold 3 = -0.39780542762657006)\n",
            "CPU time: 0.6500163078308105 seconds\n",
            "100%|██████████| 5/5 [00:03<00:00,  1.40trial/s, best loss: 0.42447896705734856]\n",
            "\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "{'ce__strategy': 'random_projection', 'est__max_depth': 5, 'est__strategy': 'LightGBM', 'est__subsample': 0.721325194257596, 'fs__threshold': 0.1, 'ne__numerical_strategy': 'mean'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neK5SQg9NRj5",
        "colab_type": "text"
      },
      "source": [
        "# PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdY_iBJlast7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Predictor().fit_predict(best, data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}